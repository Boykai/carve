{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAR Single Node on MovieLens (Python, CPU)\n",
    "\n",
    "Simple Algorithm for Recommendation (SAR) is a fast and scalable algorithm for personalized recommendations based on user transaction history. It produces easily explainable and interpretable recommendations and handles \"cold item\" and \"semi-cold user\" scenarios. SAR is a kind of neighborhood based algorithm (as discussed in [Recommender Systems by Aggarwal](https://dl.acm.org/citation.cfm?id=2931100)) which is intended for ranking top items for each user. More details about SAR can be found in the [deep dive notebook](../02_model_collaborative_filtering/sar_deep_dive.ipynb). \n",
    "\n",
    "SAR recommends items that are most ***similar*** to the ones that the user already has an existing ***affinity*** for. Two items are ***similar*** if the users that interacted with one item are also likely to have interacted with the other. A user has an ***affinity*** to an item if they have interacted with it in the past.\n",
    "\n",
    "### Advantages of SAR:\n",
    "- High accuracy for an easy to train and deploy algorithm\n",
    "- Fast training, only requiring simple counting to construct matrices used at prediction time. \n",
    "- Fast scoring, only involving multiplication of the similarity matrix with an affinity vector\n",
    "\n",
    "### Notes to use SAR properly:\n",
    "- Since it does not use item or user features, it can be at a disadvantage against algorithms that do.\n",
    "- It's memory-hungry, requiring the creation of an $mxm$ sparse square matrix (where $m$ is the number of items). This can also be a problem for many matrix factorization algorithms.\n",
    "- SAR favors an implicit rating scenario and it does not predict ratings.\n",
    "\n",
    "This notebook provides an example of how to utilize and evaluate SAR in Python on a CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Global Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.13 (default, Mar 29 2022, 02:18:16) \n",
      "[GCC 7.5.0]\n",
      "Pandas version: 1.3.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    logloss,\n",
    "    rsquared,\n",
    "    exp_var\n",
    ")\n",
    "from recommenders.models.sar import SAR\n",
    "import sys\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Data\n",
    "\n",
    "SAR is intended to be used on interactions with the following schema:\n",
    "`<User ID>, <Item ID>,<Time>,[<Event Type>], [<Event Weight>]`. \n",
    "\n",
    "Each row represents a single interaction between a user and an item. These interactions might be different types of events on an e-commerce website, such as a user clicking to view an item, adding it to a shopping basket, following a recommendation link, and so on. Each event type can be assigned a different weight, for example, we might assign a “buy” event a weight of 10, while a “view” event might only have a weight of 1.\n",
    "\n",
    "The MovieLens dataset is well formatted interactions of Users providing Ratings to Movies (movie ratings are used as the event weight) - we will use it for the rest of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download and use the MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baki/anaconda/envs/carve37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (6,7,8,9,10,11,12,14,15,17,18,20,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>genres_0</th>\n",
       "      <th>genres_1</th>\n",
       "      <th>genres_2</th>\n",
       "      <th>genres_3</th>\n",
       "      <th>genres_4</th>\n",
       "      <th>...</th>\n",
       "      <th>categories_2</th>\n",
       "      <th>color_0</th>\n",
       "      <th>color_1</th>\n",
       "      <th>color_2</th>\n",
       "      <th>tags_0</th>\n",
       "      <th>tags_1</th>\n",
       "      <th>tags_2</th>\n",
       "      <th>description_0</th>\n",
       "      <th>description_1</th>\n",
       "      <th>description_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.141416e+09</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>figurine</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>animated cartoon</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.439472e+09</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>figurine</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>animated cartoon</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.573944e+09</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>figurine</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>animated cartoon</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.586259e+08</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>figurine</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>animated cartoon</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.904925e+08</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>figurine</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>animated cartoon</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  movieId  userId  rating     timestamp   genres_0    genres_1  \\\n",
       "0           0        1     2.0     3.5  1.141416e+09  Adventure   Animation   \n",
       "1           1        1     3.0     4.0  1.439472e+09  Adventure   Animation   \n",
       "2           2        1     4.0     3.0  1.573944e+09  Adventure   Animation   \n",
       "3           3        1     5.0     4.0  8.586259e+08  Adventure   Animation   \n",
       "4           4        1     8.0     4.0  8.904925e+08  Adventure   Animation   \n",
       "\n",
       "    genres_2 genres_3  genres_4  ... categories_2 color_0  color_1 color_2  \\\n",
       "0   Children   Comedy   Fantasy  ...          NaN   Brown   Yellow     NaN   \n",
       "1   Children   Comedy   Fantasy  ...          NaN   Brown   Yellow     NaN   \n",
       "2   Children   Comedy   Fantasy  ...          NaN   Brown   Yellow     NaN   \n",
       "3   Children   Comedy   Fantasy  ...          NaN   Brown   Yellow     NaN   \n",
       "4   Children   Comedy   Fantasy  ...          NaN   Brown   Yellow     NaN   \n",
       "\n",
       "     tags_0 tags_1             tags_2 description_0 description_1  \\\n",
       "0  figurine   LEGO   animated cartoon           map           NaN   \n",
       "1  figurine   LEGO   animated cartoon           map           NaN   \n",
       "2  figurine   LEGO   animated cartoon           map           NaN   \n",
       "3  figurine   LEGO   animated cartoon           map           NaN   \n",
       "4  figurine   LEGO   animated cartoon           map           NaN   \n",
       "\n",
       "  description_2  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = movielens.load_pandas_df(\n",
    "#    size=MOVIELENS_DATA_SIZE\n",
    "#)\n",
    "data = pd.read_csv(\"../../carve/datasets/carve-movielens-prepared.csv\")\n",
    "# Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "data['rating'] = data['rating'].astype(np.float32)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the data using the python random splitter provided in utilities:\n",
    "\n",
    "We split the full dataset into a `train` and `test` dataset to evaluate performance of the algorithm against a held-out set not seen during training. Because SAR generates recommendations based on user preferences, all users that are in the test set must also exist in the training set. For this case, we can use the provided `python_stratified_split` function which holds out a percentage (in this case 25%) of items from each user, but ensures all users are in both `train` and `test` datasets. Other options are available in the `dataset.python_splitters` module which provide more control over how the split occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(data, ratio=0.75, col_user='userId', col_item='movieId', seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Total Ratings: 16547805\n",
      "Unique Users: 162541\n",
      "Unique Items: 43742\n",
      "\n",
      "Test:\n",
      "Total Ratings: 5515391\n",
      "Unique Users: 162541\n",
      "Unique Items: 35045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train['userId'].unique()),\n",
    "    train_items=len(train['movieId'].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test['userId'].unique()),\n",
    "    test_items=len(test['movieId'].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Train the SAR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Instantiate the SAR algorithm and set the index\n",
    "\n",
    "We will use the single node implementation of SAR and specify the column names to match our dataset (timestamp is an optional column that is used and can be removed if your dataset does not contain it).\n",
    "\n",
    "Other options are specified to control the behavior of the algorithm as described in the [deep dive notebook](../02_model_collaborative_filtering/sar_deep_dive.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "model = SAR(\n",
    "    col_user=\"userId\",\n",
    "    col_item=\"movieId\",\n",
    "    col_rating=\"rating\",\n",
    "    col_timestamp=\"timestamp\",\n",
    "    similarity_type=\"jaccard\", \n",
    "    time_decay_coefficient=30, \n",
    "    timedecay_formula=True,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train the SAR model on our training data, and get the top-k recommendations for our testing data\n",
    "\n",
    "SAR first computes an item-to-item ***co-occurence matrix***. Co-occurence represents the number of times two items appear together for any given user. Once we have the co-occurence matrix, we compute an ***item similarity matrix*** by rescaling the cooccurences by a given metric (Jaccard similarity in this example). \n",
    "\n",
    "We also compute an ***affinity matrix*** to capture the strength of the relationship between each user and each item. Affinity is driven by different types (like *rating* or *viewing* a movie), and by the time of the event. \n",
    "\n",
    "Recommendations are achieved by multiplying the affinity matrix $A$ and the similarity matrix $S$. The result is a ***recommendation score matrix*** $R$. We compute the ***top-k*** results for each user in the `recommend_k_items` function seen below.\n",
    "\n",
    "A full walkthrough of the SAR algorithm can be found [here](../02_model_collaborative_filtering/sar_deep_dive.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 19:36:13,722 INFO     Collecting user affinity matrix\n",
      "2022-05-07 19:36:13,826 INFO     Calculating time-decayed affinities\n",
      "2022-05-07 19:36:18,968 INFO     Creating index columns\n",
      "2022-05-07 19:36:30,733 INFO     Calculating normalization factors\n",
      "2022-05-07 19:36:37,984 INFO     Building user affinity sparse matrix\n",
      "2022-05-07 19:36:38,667 INFO     Calculating item co-occurrence\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/baki/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 14:29:54,681 INFO     Calculating recommendation scores\n",
      "2021-05-17 14:29:54,825 INFO     Removing seen items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.17252069300002404 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    top_k = model.recommend_k_items(test, remove_seen=True)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>3.231405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>3.199445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3.154097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>3.113913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>3.054493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       1     204    3.231405\n",
       "1       1      89    3.199445\n",
       "2       1      11    3.154097\n",
       "3       1     367    3.113913\n",
       "4       1     423    3.054493"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Evaluate how well SAR performs\n",
    "\n",
    "We evaluate how well SAR performs for a few common ranking metrics provided in the `python_evaluation` module. We will consider the Mean Average Precision (MAP), Normalized Discounted Cumalative Gain (NDCG), Precision, and Recall for the top-k items per user we computed with SAR. User, item and rating column names are specified in each evaluation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_map = map_at_k(test, top_k, col_user='userId', col_item='movieId', col_rating='rating', k=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ndcg = ndcg_at_k(test, top_k, col_user='userId', col_item='movieId', col_rating='rating', k=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_precision = precision_at_k(test, top_k, col_user='userId', col_item='movieId', col_rating='rating', k=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_recall = recall_at_k(test, top_k, col_user='userId', col_item='movieId', col_rating='rating', k=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_rmse = rmse(test, top_k, col_user='userId', col_item='movieId', col_rating='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_mae = mae(test, top_k, col_user='userId', col_item='movieId', col_rating='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_rsquared = rsquared(test, top_k, col_user='userId', col_item='movieId', col_rating='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_exp_var = exp_var(test, top_k, col_user='userId', col_item='movieId', col_rating='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positivity_threshold = 2\n",
    "test_bin = test.copy()\n",
    "test_bin['rating'] = binarize(test_bin['rating'], positivity_threshold)\n",
    "\n",
    "top_k_prob = top_k.copy()\n",
    "top_k_prob['prediction'] = minmax_scale(\n",
    "    top_k_prob['prediction'].astype(float)\n",
    ")\n",
    "\n",
    "eval_logloss = logloss(test_bin, top_k_prob, col_user='userId', col_item='movieId', col_rating='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\t\n",
      "Top K:\t10\n",
      "MAP:\t0.110591\n",
      "NDCG:\t0.382461\n",
      "Precision@K:\t0.330753\n",
      "Recall@K:\t0.176385\n",
      "RMSE:\t1.253805\n",
      "MAE:\t1.048484\n",
      "R2:\t-0.569363\n",
      "Exp var:\t0.030474\n",
      "Logloss:\t0.542861\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\t\",\n",
    "      \"Top K:\\t%d\" % TOP_K,\n",
    "      \"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall,\n",
    "      \"RMSE:\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t%f\" % eval_mae,\n",
    "      \"R2:\\t%f\" % eval_rsquared,\n",
    "      \"Exp var:\\t%f\" % eval_exp_var,\n",
    "      \"Logloss:\\t%f\" % eval_logloss,\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 14:29:56,886 INFO     Calculating recommendation scores\n",
      "2021-05-17 14:29:56,893 INFO     Removing seen items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>876</td>\n",
       "      <td>523</td>\n",
       "      <td>5.0</td>\n",
       "      <td>879428378</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>876</td>\n",
       "      <td>529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>879428451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876</td>\n",
       "      <td>174</td>\n",
       "      <td>4.0</td>\n",
       "      <td>879428378</td>\n",
       "      <td>3.702239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>876</td>\n",
       "      <td>276</td>\n",
       "      <td>4.0</td>\n",
       "      <td>879428354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876</td>\n",
       "      <td>288</td>\n",
       "      <td>3.0</td>\n",
       "      <td>879428101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  prediction\n",
       "0     876     523     5.0  879428378         NaN\n",
       "1     876     529     4.0  879428451         NaN\n",
       "2     876     174     4.0  879428378    3.702239\n",
       "3     876     276     4.0  879428354         NaN\n",
       "4     876     288     3.0  879428101         NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's look at the results for a specific user\n",
    "user_id = 876\n",
    "\n",
    "ground_truth = test[test['userId']==user_id].sort_values(by='rating', ascending=False)[:TOP_K]\n",
    "prediction = model.recommend_k_items(pd.DataFrame(dict(userId=[user_id])), remove_seen=True) \n",
    "pd.merge(ground_truth, prediction, on=['userId', 'movieId'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that one of the highest rated items from the test set was recovered by the model's top-k recommendations, however the others were not. Offline evaluations are difficult as they can only use what was seen previously in the test set and may not represent the user's actual preferences across the entire set of items. Adjustments to how the data is split, algorithm is used and hyper-parameters can improve the results here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.11059057578638949,
       "encoder": "json",
       "name": "map",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "map"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.3824612290501957,
       "encoder": "json",
       "name": "ndcg",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "ndcg"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.33075291622481445,
       "encoder": "json",
       "name": "precision",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "precision"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.1763854474342893,
       "encoder": "json",
       "name": "recall",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "recall"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.4035077240000646,
       "encoder": "json",
       "name": "train_time",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "train_time"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.17252069300002404,
       "encoder": "json",
       "name": "test_time",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "test_time"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Record results with papermill for tests - ignore this cell\n",
    "sb.glue(\"map\", eval_map)\n",
    "sb.glue(\"ndcg\", eval_ndcg)\n",
    "sb.glue(\"precision\", eval_precision)\n",
    "sb.glue(\"recall\", eval_recall)\n",
    "sb.glue(\"train_time\", train_time.interval)\n",
    "sb.glue(\"test_time\", test_time.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "4f84c144bfee29b369a80d7c677099ea4aaf3daf02edda0f85102571f5b1d691"
  },
  "kernelspec": {
   "display_name": "reco_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
